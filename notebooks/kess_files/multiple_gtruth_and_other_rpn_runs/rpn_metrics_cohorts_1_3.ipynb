{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for RPN and GCViT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming Files\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.21 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import pandas as pd\n",
    "from project.dataset import Dataset, VALDODataset\n",
    "from project.preprocessing import NiftiToTensorTransform\n",
    "from torch.utils.data import DataLoader\n",
    "from project.utils import collatev2, compute_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset()\n",
    "\n",
    "data = pd.read_csv('targets.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('has_microbleed_slice == 1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_loaders(data,\n",
    "                 cohort,\n",
    "                 batch_size,\n",
    "                 test_size=0.2,\n",
    "                 random_state=12,\n",
    "                 target_shape=(300, 300),\n",
    "                 rpn_mode=True,\n",
    "                 logger=None\n",
    "                ):\n",
    "    data = data[data.cohort == cohort]\n",
    "    \n",
    "    s = f'Creating loaders for Cohort {cohort}\\n'\n",
    "\n",
    "    data_train, data_test = train_test_split(\n",
    "        data,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    s += f'TRAIN & TEST: {data_train.shape, data_test.shape}\\n'\n",
    "\n",
    "    paths = data_train.mri.unique().tolist()\n",
    "    s += f'Total Unique MRI Samples in data_train: {len(paths)}\\n'\n",
    "    \n",
    "    global_min, global_max = compute_statistics(paths)\n",
    "    s += f'GLOBAL MIN & MAX {global_min, global_max}\\n'\n",
    "\n",
    "    transform = NiftiToTensorTransform(\n",
    "        target_shape=target_shape,\n",
    "        rpn_mode=rpn_mode,\n",
    "        normalization=(global_min, global_max)\n",
    "    )\n",
    "\n",
    "    train_set = VALDODataset(\n",
    "        cases=data_train.mri.tolist(),\n",
    "        masks=data_train.masks.tolist(),\n",
    "        target=data_train.target.tolist(),\n",
    "        transform=transform\n",
    "    )\n",
    "    val_set = VALDODataset(\n",
    "        cases=data_test.mri.tolist(),\n",
    "        masks=data_test.masks.tolist(),\n",
    "        target=data_test.target.tolist(),\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    if logger != None:\n",
    "        logger.info(s)\n",
    "    else:\n",
    "        print(s)\n",
    "    \n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders for Cohort 1\n",
      "TRAIN & TEST: ((36, 7), (9, 7))\n",
      "Total Unique MRI Samples in data_train: 8\n",
      "GLOBAL MIN & MAX (0.0, 1417.92822265625)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1, v1 = make_loaders(\n",
    "    data=data,\n",
    "    cohort=1,\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating loaders for Cohort 3\n",
      "TRAIN & TEST: ((37, 7), (10, 7))\n",
      "Total Unique MRI Samples in data_train: 26\n",
      "GLOBAL MIN & MAX (0.0, 664.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t3, v3 = make_loaders(\n",
    "    data=data,\n",
    "    cohort=3,\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "train_set = ConcatDataset([t1, t3])\n",
    "val_set = ConcatDataset([v1, v3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = DataLoader(\n",
    "    train_set,\n",
    "    shuffle=True,\n",
    "    batch_size=20,\n",
    "    collate_fn=collatev2\n",
    ")\n",
    "vl = DataLoader(\n",
    "    val_set,\n",
    "    shuffle=True,\n",
    "    batch_size=20,\n",
    "    collate_fn=collatev2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPN metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming Files\\Python\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from project.model import RPN\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "\n",
    "rpn_model = RPN(\n",
    "    input_dim=512,\n",
    "    output_dim=4,\n",
    "    image_size=300,\n",
    "    nh=4,\n",
    "    pretrained=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_model.load_state_dict(torch.load('weights/RPN_cohorts_1_3_50_epochs_mse_loss_Nov_06_2024_205918.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.detection import intersection_over_union\n",
    "from torchvision.ops import box_area\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upcast(t: Tensor) -> Tensor:\n",
    "    # Protects from numerical overflows in multiplications by upcasting to the equivalent higher type\n",
    "    if t.is_floating_point():\n",
    "        return t if t.dtype in (torch.float32, torch.float64) else t.float()\n",
    "    else:\n",
    "        return t if t.dtype in (torch.int32, torch.int64) else t.int()\n",
    "\n",
    "def _box_inter_union(boxes1: Tensor, boxes2: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    area1 = box_area(boxes1)\n",
    "    area2 = box_area(boxes2)\n",
    "\n",
    "    lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
    "    rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]\n",
    "\n",
    "    wh = _upcast(rb - lt).clamp(min=0)  # [N,M,2]\n",
    "    inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n",
    "\n",
    "    union = area1[:, None] + area2 - inter\n",
    "\n",
    "    return inter, union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "d:\\Programming Files\\Python\\Lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    }
   ],
   "source": [
    "tl_iou_scores = []\n",
    "tl_preds = []\n",
    "tl_truth = []\n",
    "tl_cases = []\n",
    "tl_targets = []\n",
    "tl_precision_scores = []\n",
    "tl_recall_scores = []\n",
    "tl_f1_scores = []\n",
    "tl_counter = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tl:\n",
    "        for i in range(len(batch)):\n",
    "            slices, masks, target, case = batch[i]\n",
    "            x = slices.squeeze(1).repeat(1, 3, 1, 1).float().to(device)\n",
    "            T = masks.squeeze(1).float().to(device)/image_size\n",
    "\n",
    "            y = rpn_model(x, target)\n",
    "\n",
    "            tl_preds.append((y *  image_size).squeeze().detach().cpu().numpy())\n",
    "            tl_truth.append((T[target] * image_size).squeeze().detach().cpu().numpy())\n",
    "            tl_cases.append(case)\n",
    "            tl_targets.append(target)\n",
    "\n",
    "            tl_iou_score = intersection_over_union(y * image_size, T[target] * image_size)\n",
    "\n",
    "            tl_inter, tl_union = _box_inter_union(y * image_size, T[target] * image_size)\n",
    "\n",
    "            tl_precision_score = (tl_inter / box_area(y * image_size))\n",
    "            tl_recall_score = (tl_inter / box_area(T[target] * image_size))\n",
    "\n",
    "            if any([tl_precision_score, tl_recall_score]) == 0:\n",
    "                tl_f1_score = 0\n",
    "                tl_f1_scores.append(tl_f1_score)\n",
    "            else:\n",
    "                tl_f1_score = (2 * (tl_precision_score * tl_recall_score)) / (tl_precision_score + tl_recall_score)\n",
    "                tl_f1_scores.append(tl_f1_score.detach().cpu().numpy())\n",
    "\n",
    "            tl_iou_scores.append(tl_iou_score.detach().cpu().numpy())\n",
    "            tl_precision_scores.append(tl_precision_score.squeeze().squeeze().detach().cpu().numpy())\n",
    "            tl_recall_scores.append(tl_recall_score.squeeze().squeeze().detach().cpu().numpy())\n",
    "            tl_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_score_dict = {\n",
    "    'Case': tl_cases,\n",
    "    'Target': tl_targets,\n",
    "    'Ground_Truth': tl_truth,\n",
    "    'Predictions': tl_preds,\n",
    "    'IOU': tl_iou_scores,\n",
    "    'Precision': tl_precision_scores,\n",
    "    'Recall': tl_recall_scores,\n",
    "    'F1': tl_f1_scores\n",
    "}\n",
    "\n",
    "tl_score_df = pd.DataFrame(tl_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Target</th>\n",
       "      <th>Ground_Truth</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>IOU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>19</td>\n",
       "      <td>[134.17969, 73.828125, 240.82031, 156.44531]</td>\n",
       "      <td>[157.22818, 87.86252, 237.61316, 138.9068]</td>\n",
       "      <td>0.4657243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4657243</td>\n",
       "      <td>[[0.6354869]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>35</td>\n",
       "      <td>[92.578125, 111.328125, 212.10938, 230.85938]</td>\n",
       "      <td>[109.46289, 121.4304, 155.45508, 169.5667]</td>\n",
       "      <td>0.15495081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15495081</td>\n",
       "      <td>[[0.26832452]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>17</td>\n",
       "      <td>[94.921875, 104.88281, 172.85156, 177.53906]</td>\n",
       "      <td>[94.61526, 139.07092, 122.45817, 157.87566]</td>\n",
       "      <td>0.0913597</td>\n",
       "      <td>0.98898757</td>\n",
       "      <td>0.09145273</td>\n",
       "      <td>[[0.16742362]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>19</td>\n",
       "      <td>[20.507812, 86.13281, 91.40625, 167.57812]</td>\n",
       "      <td>[30.670006, 103.67617, 70.89777, 155.26727]</td>\n",
       "      <td>0.3594165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3594165</td>\n",
       "      <td>[[0.5287806]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>10</td>\n",
       "      <td>[18.75, 62.109375, 140.625, 182.8125]</td>\n",
       "      <td>[41.99595, 86.165535, 114.54622, 145.35579]</td>\n",
       "      <td>0.2919148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2919148</td>\n",
       "      <td>[[0.4519103]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>13</td>\n",
       "      <td>[1.171875, 134.76562, 121.875, 255.46875]</td>\n",
       "      <td>[31.216421, 161.09384, 110.042755, 243.97403]</td>\n",
       "      <td>0.44842005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.44842005</td>\n",
       "      <td>[[0.6191851]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>18</td>\n",
       "      <td>[111.91406, 151.75781, 172.85156, 212.69531]</td>\n",
       "      <td>[132.14326, 149.66022, 139.83173, 204.15344]</td>\n",
       "      <td>0.10801477</td>\n",
       "      <td>0.9615072</td>\n",
       "      <td>0.10848388</td>\n",
       "      <td>[[0.1949699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>16</td>\n",
       "      <td>[122.46094, 97.265625, 191.01562, 208.59375]</td>\n",
       "      <td>[123.80505, 104.928024, 154.35136, 184.90591]</td>\n",
       "      <td>0.3201007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.32010072</td>\n",
       "      <td>[[0.48496407]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>32</td>\n",
       "      <td>[71.484375, 100.19531, 134.17969, 162.30469]</td>\n",
       "      <td>[84.65934, 98.04216, 102.48688, 140.64664]</td>\n",
       "      <td>0.18338834</td>\n",
       "      <td>0.9494619</td>\n",
       "      <td>0.18519612</td>\n",
       "      <td>[[0.30993772]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>13</td>\n",
       "      <td>[60.9375, 90.82031, 121.28906, 151.75781]</td>\n",
       "      <td>[68.13056, 121.25951, 97.509964, 138.18495]</td>\n",
       "      <td>0.13521035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.13521034</td>\n",
       "      <td>[[0.23821196]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Case  Target  \\\n",
       "0   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      19   \n",
       "1   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      35   \n",
       "2   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      17   \n",
       "3   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      19   \n",
       "4   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      10   \n",
       "..                                                ...     ...   \n",
       "68  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      13   \n",
       "69  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      18   \n",
       "70  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      16   \n",
       "71  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      32   \n",
       "72  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      13   \n",
       "\n",
       "                                     Ground_Truth  \\\n",
       "0    [134.17969, 73.828125, 240.82031, 156.44531]   \n",
       "1   [92.578125, 111.328125, 212.10938, 230.85938]   \n",
       "2    [94.921875, 104.88281, 172.85156, 177.53906]   \n",
       "3      [20.507812, 86.13281, 91.40625, 167.57812]   \n",
       "4           [18.75, 62.109375, 140.625, 182.8125]   \n",
       "..                                            ...   \n",
       "68      [1.171875, 134.76562, 121.875, 255.46875]   \n",
       "69   [111.91406, 151.75781, 172.85156, 212.69531]   \n",
       "70   [122.46094, 97.265625, 191.01562, 208.59375]   \n",
       "71   [71.484375, 100.19531, 134.17969, 162.30469]   \n",
       "72      [60.9375, 90.82031, 121.28906, 151.75781]   \n",
       "\n",
       "                                      Predictions         IOU   Precision  \\\n",
       "0      [157.22818, 87.86252, 237.61316, 138.9068]   0.4657243         1.0   \n",
       "1      [109.46289, 121.4304, 155.45508, 169.5667]  0.15495081         1.0   \n",
       "2     [94.61526, 139.07092, 122.45817, 157.87566]   0.0913597  0.98898757   \n",
       "3     [30.670006, 103.67617, 70.89777, 155.26727]   0.3594165         1.0   \n",
       "4     [41.99595, 86.165535, 114.54622, 145.35579]   0.2919148         1.0   \n",
       "..                                            ...         ...         ...   \n",
       "68  [31.216421, 161.09384, 110.042755, 243.97403]  0.44842005         1.0   \n",
       "69   [132.14326, 149.66022, 139.83173, 204.15344]  0.10801477   0.9615072   \n",
       "70  [123.80505, 104.928024, 154.35136, 184.90591]   0.3201007         1.0   \n",
       "71     [84.65934, 98.04216, 102.48688, 140.64664]  0.18338834   0.9494619   \n",
       "72    [68.13056, 121.25951, 97.509964, 138.18495]  0.13521035         1.0   \n",
       "\n",
       "        Recall              F1  \n",
       "0    0.4657243   [[0.6354869]]  \n",
       "1   0.15495081  [[0.26832452]]  \n",
       "2   0.09145273  [[0.16742362]]  \n",
       "3    0.3594165   [[0.5287806]]  \n",
       "4    0.2919148   [[0.4519103]]  \n",
       "..         ...             ...  \n",
       "68  0.44842005   [[0.6191851]]  \n",
       "69  0.10848388   [[0.1949699]]  \n",
       "70  0.32010072  [[0.48496407]]  \n",
       "71  0.18519612  [[0.30993772]]  \n",
       "72  0.13521034  [[0.23821196]]  \n",
       "\n",
       "[73 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n",
      "INFO:nibabel.global:pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    }
   ],
   "source": [
    "vl_iou_scores = []\n",
    "vl_preds = []\n",
    "vl_truth = []\n",
    "vl_cases = []\n",
    "vl_targets = []\n",
    "vl_precision_scores = []\n",
    "vl_recall_scores = []\n",
    "vl_f1_scores = []\n",
    "vl_counter = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in vl:\n",
    "        for i in range(len(batch)):\n",
    "            slices, masks, target, case = batch[i]\n",
    "            x = slices.squeeze(1).repeat(1, 3, 1, 1).float().to(device)\n",
    "            T = masks.squeeze(1).float().to(device)/image_size\n",
    "\n",
    "            y = rpn_model(x, target)\n",
    "\n",
    "            vl_preds.append((y *  image_size).squeeze().detach().cpu().numpy())\n",
    "            vl_truth.append((T[target] * image_size).squeeze().detach().cpu().numpy())\n",
    "            vl_cases.append(case)\n",
    "            vl_targets.append(target)\n",
    "\n",
    "            vl_iou_score = intersection_over_union(y * image_size, T[target] * image_size)\n",
    "\n",
    "            vl_inter, vl_union = _box_inter_union(y * image_size, T[target] * image_size)\n",
    "\n",
    "            vl_precision_score = (vl_inter / box_area(y * image_size))\n",
    "            vl_recall_score = (vl_inter / box_area(T[target] * image_size))\n",
    "\n",
    "            if any([vl_precision_score, vl_recall_score]) == 0:\n",
    "                vl_f1_score = 0\n",
    "                vl_f1_scores.append(vl_f1_score)\n",
    "            else:\n",
    "                vl_f1_score = (2 * (vl_precision_score * vl_recall_score)) / (vl_precision_score + vl_recall_score)\n",
    "                vl_f1_scores.append(vl_f1_score.detach().cpu().numpy())\n",
    "\n",
    "            vl_iou_scores.append(vl_iou_score.detach().cpu().numpy())\n",
    "            vl_precision_scores.append(vl_precision_score.squeeze().squeeze().detach().cpu().numpy())\n",
    "            vl_recall_scores.append(vl_recall_score.squeeze().squeeze().detach().cpu().numpy())\n",
    "            vl_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl_score_dict = {\n",
    "    'Case': vl_cases,\n",
    "    'Target': vl_targets,\n",
    "    'Ground_Truth': vl_truth,\n",
    "    'Predictions': vl_preds,\n",
    "    'IOU': vl_iou_scores,\n",
    "    'Precision': vl_precision_scores,\n",
    "    'Recall': vl_recall_scores,\n",
    "    'F1': vl_f1_scores\n",
    "}\n",
    "\n",
    "vl_score_df = pd.DataFrame(vl_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Target</th>\n",
       "      <th>Ground_Truth</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>IOU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>15</td>\n",
       "      <td>[80.859375, 116.015625, 201.5625, 235.54688]</td>\n",
       "      <td>[112.96271, 112.21169, 145.991, 172.40048]</td>\n",
       "      <td>0.12796262</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.12907693</td>\n",
       "      <td>[[0.2268916]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>14</td>\n",
       "      <td>[2.34375, 135.9375, 121.875, 255.46875]</td>\n",
       "      <td>[68.025665, 149.52098, 130.67418, 203.80186]</td>\n",
       "      <td>0.1979628</td>\n",
       "      <td>0.8595469</td>\n",
       "      <td>0.20458055</td>\n",
       "      <td>[[0.33049908]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>18</td>\n",
       "      <td>[45.703125, 147.65625, 165.23438, 267.1875]</td>\n",
       "      <td>[68.13995, 117.33127, 170.99318, 202.72847]</td>\n",
       "      <td>0.30169472</td>\n",
       "      <td>0.6087869</td>\n",
       "      <td>0.3742518</td>\n",
       "      <td>[[0.46354145]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>24</td>\n",
       "      <td>[21.09375, 59.765625, 102.53906, 176.36719]</td>\n",
       "      <td>[61.147186, 99.77289, 121.926544, 172.24318]</td>\n",
       "      <td>0.27515808</td>\n",
       "      <td>0.68101865</td>\n",
       "      <td>0.3158673</td>\n",
       "      <td>[[0.43156695]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>26</td>\n",
       "      <td>[110.15625, 119.53125, 233.20312, 241.40625]</td>\n",
       "      <td>[103.32042, 104.172714, 169.84447, 172.16055]</td>\n",
       "      <td>0.19180517</td>\n",
       "      <td>0.6945545</td>\n",
       "      <td>0.20947443</td>\n",
       "      <td>[[0.32187334]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>12</td>\n",
       "      <td>[5.859375, 116.015625, 126.5625, 236.71875]</td>\n",
       "      <td>[52.03413, 132.91034, 89.099205, 187.7659]</td>\n",
       "      <td>0.139556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139556</td>\n",
       "      <td>[[0.24493048]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>23</td>\n",
       "      <td>[106.640625, 76.171875, 226.17188, 196.875]</td>\n",
       "      <td>[130.23915, 73.80242, 213.99149, 169.5902]</td>\n",
       "      <td>0.5349291</td>\n",
       "      <td>0.97526354</td>\n",
       "      <td>0.54228675</td>\n",
       "      <td>[[0.6970082]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>11</td>\n",
       "      <td>[20.507812, 151.17188, 81.44531, 212.10938]</td>\n",
       "      <td>[92.7193, 145.53961, 143.10303, 195.79063]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>14</td>\n",
       "      <td>[39.84375, 82.03125, 100.78125, 142.96875]</td>\n",
       "      <td>[50.429844, 90.35767, 106.030174, 161.87347]</td>\n",
       "      <td>0.52553684</td>\n",
       "      <td>0.6662073</td>\n",
       "      <td>0.7133777</td>\n",
       "      <td>[[0.6889861]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>22</td>\n",
       "      <td>[16.40625, 69.140625, 135.35156, 162.89062]</td>\n",
       "      <td>[81.876114, 107.58381, 153.32457, 165.63576]</td>\n",
       "      <td>0.23964733</td>\n",
       "      <td>0.7130557</td>\n",
       "      <td>0.26522502</td>\n",
       "      <td>[[0.38663793]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>27</td>\n",
       "      <td>[119.53125, 148.24219, 180.46875, 209.76562]</td>\n",
       "      <td>[47.78999, 77.376625, 147.50412, 169.67326]</td>\n",
       "      <td>0.0485303</td>\n",
       "      <td>0.06513861</td>\n",
       "      <td>0.15990269</td>\n",
       "      <td>[[0.09256824]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>14</td>\n",
       "      <td>[92.578125, 52.734375, 215.625, 174.60938]</td>\n",
       "      <td>[100.90897, 105.04204, 168.78535, 180.05785]</td>\n",
       "      <td>0.30729723</td>\n",
       "      <td>0.927369</td>\n",
       "      <td>0.31487548</td>\n",
       "      <td>[[0.47012606]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>26</td>\n",
       "      <td>[70.3125, 48.046875, 188.67188, 167.57812]</td>\n",
       "      <td>[141.99721, 95.41432, 213.875, 163.18686]</td>\n",
       "      <td>0.19950277</td>\n",
       "      <td>0.6493615</td>\n",
       "      <td>0.22358921</td>\n",
       "      <td>[[0.33264244]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>18</td>\n",
       "      <td>[45.703125, 124.21875, 165.23438, 243.75]</td>\n",
       "      <td>[88.27091, 89.926315, 148.5017, 182.10306]</td>\n",
       "      <td>0.21319504</td>\n",
       "      <td>0.6279708</td>\n",
       "      <td>0.24401493</td>\n",
       "      <td>[[0.35146046]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>28</td>\n",
       "      <td>[34.570312, 93.75, 132.42188, 175.19531]</td>\n",
       "      <td>[91.709175, 109.322754, 142.17609, 162.57506]</td>\n",
       "      <td>0.25539508</td>\n",
       "      <td>0.80672073</td>\n",
       "      <td>0.27204105</td>\n",
       "      <td>[[0.40687603]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>9</td>\n",
       "      <td>[124.80469, 168.75, 185.74219, 230.27344]</td>\n",
       "      <td>[108.53221, 132.78905, 134.52104, 196.91226]</td>\n",
       "      <td>0.05321623</td>\n",
       "      <td>0.16419838</td>\n",
       "      <td>0.07298703</td>\n",
       "      <td>[[0.10105471]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>25</td>\n",
       "      <td>[63.28125, 94.921875, 125.390625, 157.03125]</td>\n",
       "      <td>[52.78944, 68.000565, 116.690094, 181.98172]</td>\n",
       "      <td>0.42398408</td>\n",
       "      <td>0.45544085</td>\n",
       "      <td>0.859916</td>\n",
       "      <td>[[0.5954899]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>13</td>\n",
       "      <td>[107.8125, 71.484375, 228.51562, 192.1875]</td>\n",
       "      <td>[65.28886, 90.15245, 125.31116, 186.91566]</td>\n",
       "      <td>0.090624556</td>\n",
       "      <td>0.29153594</td>\n",
       "      <td>0.11621923</td>\n",
       "      <td>[[0.16618836]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...</td>\n",
       "      <td>29</td>\n",
       "      <td>[43.359375, 91.99219, 114.25781, 167.57812]</td>\n",
       "      <td>[81.17098, 97.21012, 145.5621, 179.59317]</td>\n",
       "      <td>0.27932096</td>\n",
       "      <td>0.43890098</td>\n",
       "      <td>0.43446293</td>\n",
       "      <td>[[0.4366707]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Case  Target  \\\n",
       "0   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      15   \n",
       "1   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      14   \n",
       "2   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      18   \n",
       "3   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      24   \n",
       "4   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      26   \n",
       "5   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      12   \n",
       "6   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      23   \n",
       "7   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      11   \n",
       "8   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      14   \n",
       "9   d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      22   \n",
       "10  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      27   \n",
       "11  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      14   \n",
       "12  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      26   \n",
       "13  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      18   \n",
       "14  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      28   \n",
       "15  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...       9   \n",
       "16  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      25   \n",
       "17  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      13   \n",
       "18  d:\\Github\\Thesis and ML Project\\Dataset\\VALDO_...      29   \n",
       "\n",
       "                                    Ground_Truth  \\\n",
       "0   [80.859375, 116.015625, 201.5625, 235.54688]   \n",
       "1        [2.34375, 135.9375, 121.875, 255.46875]   \n",
       "2    [45.703125, 147.65625, 165.23438, 267.1875]   \n",
       "3    [21.09375, 59.765625, 102.53906, 176.36719]   \n",
       "4   [110.15625, 119.53125, 233.20312, 241.40625]   \n",
       "5    [5.859375, 116.015625, 126.5625, 236.71875]   \n",
       "6    [106.640625, 76.171875, 226.17188, 196.875]   \n",
       "7    [20.507812, 151.17188, 81.44531, 212.10938]   \n",
       "8     [39.84375, 82.03125, 100.78125, 142.96875]   \n",
       "9    [16.40625, 69.140625, 135.35156, 162.89062]   \n",
       "10  [119.53125, 148.24219, 180.46875, 209.76562]   \n",
       "11    [92.578125, 52.734375, 215.625, 174.60938]   \n",
       "12    [70.3125, 48.046875, 188.67188, 167.57812]   \n",
       "13     [45.703125, 124.21875, 165.23438, 243.75]   \n",
       "14      [34.570312, 93.75, 132.42188, 175.19531]   \n",
       "15     [124.80469, 168.75, 185.74219, 230.27344]   \n",
       "16  [63.28125, 94.921875, 125.390625, 157.03125]   \n",
       "17    [107.8125, 71.484375, 228.51562, 192.1875]   \n",
       "18   [43.359375, 91.99219, 114.25781, 167.57812]   \n",
       "\n",
       "                                      Predictions          IOU   Precision  \\\n",
       "0      [112.96271, 112.21169, 145.991, 172.40048]   0.12796262      0.9368   \n",
       "1    [68.025665, 149.52098, 130.67418, 203.80186]    0.1979628   0.8595469   \n",
       "2     [68.13995, 117.33127, 170.99318, 202.72847]   0.30169472   0.6087869   \n",
       "3    [61.147186, 99.77289, 121.926544, 172.24318]   0.27515808  0.68101865   \n",
       "4   [103.32042, 104.172714, 169.84447, 172.16055]   0.19180517   0.6945545   \n",
       "5      [52.03413, 132.91034, 89.099205, 187.7659]     0.139556         1.0   \n",
       "6      [130.23915, 73.80242, 213.99149, 169.5902]    0.5349291  0.97526354   \n",
       "7      [92.7193, 145.53961, 143.10303, 195.79063]          0.0         0.0   \n",
       "8    [50.429844, 90.35767, 106.030174, 161.87347]   0.52553684   0.6662073   \n",
       "9    [81.876114, 107.58381, 153.32457, 165.63576]   0.23964733   0.7130557   \n",
       "10    [47.78999, 77.376625, 147.50412, 169.67326]    0.0485303  0.06513861   \n",
       "11   [100.90897, 105.04204, 168.78535, 180.05785]   0.30729723    0.927369   \n",
       "12      [141.99721, 95.41432, 213.875, 163.18686]   0.19950277   0.6493615   \n",
       "13     [88.27091, 89.926315, 148.5017, 182.10306]   0.21319504   0.6279708   \n",
       "14  [91.709175, 109.322754, 142.17609, 162.57506]   0.25539508  0.80672073   \n",
       "15   [108.53221, 132.78905, 134.52104, 196.91226]   0.05321623  0.16419838   \n",
       "16   [52.78944, 68.000565, 116.690094, 181.98172]   0.42398408  0.45544085   \n",
       "17     [65.28886, 90.15245, 125.31116, 186.91566]  0.090624556  0.29153594   \n",
       "18      [81.17098, 97.21012, 145.5621, 179.59317]   0.27932096  0.43890098   \n",
       "\n",
       "        Recall              F1  \n",
       "0   0.12907693   [[0.2268916]]  \n",
       "1   0.20458055  [[0.33049908]]  \n",
       "2    0.3742518  [[0.46354145]]  \n",
       "3    0.3158673  [[0.43156695]]  \n",
       "4   0.20947443  [[0.32187334]]  \n",
       "5     0.139556  [[0.24493048]]  \n",
       "6   0.54228675   [[0.6970082]]  \n",
       "7          0.0               0  \n",
       "8    0.7133777   [[0.6889861]]  \n",
       "9   0.26522502  [[0.38663793]]  \n",
       "10  0.15990269  [[0.09256824]]  \n",
       "11  0.31487548  [[0.47012606]]  \n",
       "12  0.22358921  [[0.33264244]]  \n",
       "13  0.24401493  [[0.35146046]]  \n",
       "14  0.27204105  [[0.40687603]]  \n",
       "15  0.07298703  [[0.10105471]]  \n",
       "16    0.859916   [[0.5954899]]  \n",
       "17  0.11621923  [[0.16618836]]  \n",
       "18  0.43446293   [[0.4366707]]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Training Set\n",
      "IOU Score: 0.3194236594111952\n",
      "Precision Score: 0.9591874096491565\n",
      "Recall Score: 0.3223932170092243\n",
      "F1 Score: [[0.46264282]]\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for Training Set')\n",
    "print(f'IOU Score: {sum(tl_iou_scores) / len(tl_iou_scores)}')\n",
    "print(f'Precision Score: {sum(tl_precision_scores) / len(tl_precision_scores)}')\n",
    "print(f'Recall Score: {sum(tl_recall_scores) / len(tl_recall_scores)}')\n",
    "print(f'F1 Score: {sum(tl_f1_scores) / len(tl_f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Validation Set\n",
      "IOU Score: 0.23185888952330538\n",
      "Precision Score: 0.608519487475094\n",
      "Recall Score: 0.29430026600235387\n",
      "F1 Score: [[0.35500062]]\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for Validation Set')\n",
    "print(f'IOU Score: {sum(vl_iou_scores) / len(vl_iou_scores)}')\n",
    "print(f'Precision Score: {sum(vl_precision_scores) / len(vl_precision_scores)}')\n",
    "print(f'Recall Score: {sum(vl_recall_scores) / len(vl_recall_scores)}')\n",
    "print(f'F1 Score: {sum(vl_f1_scores) / len(vl_f1_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting of highest score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.patches as patches\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# num = iou_scores.index(max(iou_scores))\n",
    "\n",
    "# slices, masks, target, case = dataset[num]\n",
    "\n",
    "# truth_bbox = truth[num]\n",
    "# predicted_bbox = preds[num]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# ax.imshow(slices[target][0, 0, :], cmap='gray')\n",
    "# # Create the bounding box rectangle\n",
    "# truth_rect = patches.Rectangle(\n",
    "#     (truth_bbox[0], truth_bbox[1]),  # (x_min, y_min)\n",
    "#     truth_bbox[2] - truth_bbox[0],   # width\n",
    "#     truth_bbox[3] - truth_bbox[1],   # height\n",
    "#     linewidth=1, edgecolor='g', facecolor='none',  # red bounding box\n",
    "#     label='Truth'\n",
    "# )\n",
    "\n",
    "# # Create the bounding box rectangle\n",
    "# predicted_rect = patches.Rectangle(\n",
    "#     (predicted_bbox[0], predicted_bbox[1]),  # (x_min, y_min)\n",
    "#     predicted_bbox[2] - predicted_bbox[0],   # width\n",
    "#     predicted_bbox[3] - predicted_bbox[1],   # height\n",
    "#     linewidth=1, edgecolor='r', facecolor='none',  # red bounding box\n",
    "#     label='Prediction'\n",
    "# )\n",
    "\n",
    "# ax.set_title(f'IOU:{iou_scores[num]}, Precision: {precision_scores[num]}, Recall: {recall_scores[num]}, F1: {f1_scores[num]}')\n",
    "\n",
    "# # Add the rectangle to the axis\n",
    "# ax.add_patch(truth_rect)\n",
    "# ax.add_patch(predicted_rect)\n",
    "\n",
    "# ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
