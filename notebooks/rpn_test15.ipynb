{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bb816-7ced-4663-ba4a-f6f2c1831915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from project.dataset import Dataset, VALDODataset\n",
    "from torch.utils.data import DataLoader\n",
    "from project.preprocessing import NiftiToTensorTransform, z_score_normalization\n",
    "from project.utils import collate_fn, plot_mri_slice, plot_all_slices, plot_all_slices_from_array, collatev2\n",
    "import winsound\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from project.utils import memcheck, compute_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c96f7-7055-40cc-8dd2-6be02f0f1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime as dtt\n",
    "import os\n",
    "\n",
    "path = 'logs'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "dte = dtt.now().strftime('%b_%d_%Y_%H%M%S')\n",
    "\n",
    "logger = logging.getLogger('andy')\n",
    "fh = logging.FileHandler(f'logs/{dte}.log')\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "\n",
    "dte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a25339-7e8c-4fd6-8c0e-f5b72750ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7074a38a-c631-46d0-8095-580e6439c70d",
   "metadata": {},
   "source": [
    "### Config for fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d42175-231c-4203-aacf-6aa642d02e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.model import RPN\n",
    "\n",
    "config = {\n",
    "    'model': RPN(\n",
    "        input_dim=512,\n",
    "        output_dim=4,\n",
    "        image_size=300,\n",
    "        nh=4\n",
    "    ).to(device),\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'device': device,\n",
    "    'epochs': 50,\n",
    "    'loss': nn.SmoothL1Loss(),\n",
    "    # 'loss': nn.MSELoss(),\n",
    "    # 'loss': nn.L1Loss(),\n",
    "    'lr': 0.0001\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9947f9-fd19-493b-a910-73add09d1cdd",
   "metadata": {},
   "source": [
    "#### Load Pretrained Embedder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f911e0d2-0a6a-4141-a7ae-4c771a4ae1f6",
   "metadata": {},
   "source": [
    "model = config['model']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17bf33d9-ecdf-4c67-8980-9407d9602008",
   "metadata": {},
   "source": [
    "model.embedder.load_state_dict(torch.load('Encoder_weights_211024184155.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49457415-e7d7-4a00-a656-ed99540a53db",
   "metadata": {},
   "source": [
    "#### Load RPN Weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18a7c25e-a06d-47ef-8309-074970e1cb62",
   "metadata": {},
   "source": [
    "model = config['model']\n",
    "model.load_state_dict(torch.load('RPN_weights_241024213949.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a8966-d228-4be8-b59a-8a3c078a6d96",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461978c-bfcd-4c2d-b3f5-66c59c83659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "\n",
    "data = pd.read_csv('targets.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af41ac0-6cb0-4b25-bb6e-7dec67c0c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('has_microbleed_slice == 1').reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032365f-38f9-489b-bec1-374d5c9ba719",
   "metadata": {},
   "source": [
    "### `DataLoader` Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841431ec-6c5b-430d-af69-cfed4f10bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(data, col):\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    iqr = q3-q1\n",
    "    new = data[(data[col] < (q3 + 1.5*iqr)) & (data[col] > (q1 - 1.5*iqr))]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46304b85-cba7-4042-9d3b-b60de8510133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_loaders(data,\n",
    "                 cohort,\n",
    "                 batch_size,\n",
    "                 test_size=0.2,\n",
    "                 random_state=12,\n",
    "                 target_shape=(300, 300),\n",
    "                 rpn_mode=True,\n",
    "                 logger=None\n",
    "                ):\n",
    "    data = data[data.cohort == cohort]\n",
    "    # data = iqr(data, 'max_value')\n",
    "    \n",
    "    s = f'Creating loaders for Cohort {cohort}\\n'\n",
    "\n",
    "    data_train, data_test = train_test_split(\n",
    "        data,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    s += f'TRAIN & TEST: {data_train.shape, data_test.shape}\\n'\n",
    "\n",
    "    paths = data_train.mri.unique().tolist()\n",
    "    s += f'Total Unique MRI Samples in data_train: {len(paths)}\\n'\n",
    "    \n",
    "    global_min, global_max = compute_statistics(paths)\n",
    "    s += f'GLOBAL MIN & MAX {global_min, global_max}\\n'\n",
    "\n",
    "    transform = NiftiToTensorTransform(\n",
    "        target_shape=target_shape,\n",
    "        rpn_mode=rpn_mode,\n",
    "        normalization=(global_min, global_max)\n",
    "    )\n",
    "\n",
    "    train_set = VALDODataset(\n",
    "        cases=data_train.mri.tolist(),\n",
    "        masks=data_train.masks.tolist(),\n",
    "        target=data_train.target.tolist(),\n",
    "        transform=transform\n",
    "    )\n",
    "    val_set = VALDODataset(\n",
    "        cases=data_test.mri.tolist(),\n",
    "        masks=data_test.masks.tolist(),\n",
    "        target=data_test.target.tolist(),\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collatev2\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collatev2\n",
    "    )\n",
    "\n",
    "    if logger != None:\n",
    "        logger.info(s)\n",
    "    else:\n",
    "        print(s)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acd68f-2341-411c-9cae-2fe95e70e53b",
   "metadata": {},
   "source": [
    "### Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea8d96-05ac-4604-88d3-6b0de4874f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project import Fitter\n",
    "\n",
    "class RPNFitter(Fitter):\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        loss_history = []\n",
    "        counter = 0\n",
    "        for batch in train_loader:\n",
    "            # self.log('----------------- BATCH -----------------')\n",
    "            Y = []\n",
    "            T = []\n",
    "            for slices, masks, target, case in batch:\n",
    "                x = slices.squeeze(1).float().to(self.device)\n",
    "                masks = masks.squeeze(1).float().to(self.device)/300\n",
    "                y = self.model(x, target)\n",
    "                Y.append(y)\n",
    "                T.append(masks[target])\n",
    "            \n",
    "            losses = self.loss(torch.stack(Y), torch.stack(T))\n",
    "            self.optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            self.optimizer.step()\n",
    "            counter += 1\n",
    "            # if counter % len(batch) == 0:\n",
    "            self.log(f'Batch:\\t{counter}/{len(train_loader)}')\n",
    "            self.log(f'Batch samples:\\t{len(batch)}')\n",
    "            self.log(f'Current error:\\t{losses}\\n')\n",
    "            \n",
    "            loss_history.append(losses.detach().cpu().numpy())\n",
    "            \n",
    "            # del losses, Y, T\n",
    "            # torch.cuda.empty_cache()\n",
    "            # logger.info(f'MEMORY after CLEARING MEMORY\\t{memcheck()}')\n",
    "        \n",
    "        return loss_history\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        loss_history = []\n",
    "        with torch.inference_mode():\n",
    "            for batch in val_loader:\n",
    "                Y = []\n",
    "                T = []\n",
    "                for slices, masks, target, case in batch:\n",
    "                    x = slices.squeeze(1).float().to(self.device)\n",
    "                    masks = masks.squeeze(1).float().to(self.device)/300\n",
    "                    y = self.model(x, target)\n",
    "                    Y.append(y)\n",
    "                    T.append(masks[target])\n",
    "                losses = self.loss(torch.stack(Y), torch.stack(T))\n",
    "                loss_history.append(losses.cpu().numpy())\n",
    "        return loss_history\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009498c-d6b8-4f49-b015-590930f159ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = RPNFitter(config, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83720318-261b-4b50-9efb-179ad387e241",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a51f72-18af-45d6-99f6-70d23b37f019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tl, vl = make_loaders(\n",
    "    data=data,\n",
    "    cohort=1,\n",
    "    batch_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bf12e-3530-4b14-8fec-8bbc922b36d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thist, vhist = fitter.fit(tl, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e2991-3c8c-4a4a-b92c-e809e782c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(500, 500)\n",
    "winsound.Beep(500, 500)\n",
    "winsound.Beep(500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5d8fd-9dfe-41de-8eca-bab547cd9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "th = torch.tensor(np.array(thist))\n",
    "vh = torch.tensor(np.array(vhist))\n",
    "# print(th.shape)\n",
    "sns.lineplot(th.mean(1), label='Training history')\n",
    "sns.lineplot(vh.mean(1), label='Validation history')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc186d-b48f-46a0-8aab-33464ef15a52",
   "metadata": {},
   "source": [
    "### Save the weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88c989ba-3907-4241-9366-cf9522bc80ba",
   "metadata": {},
   "source": [
    "model = config['model']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a3e05a5-e6c9-400c-b914-07272d5f101d",
   "metadata": {},
   "source": [
    "s = f'RPN_test15_weights_{dte}.pt'\n",
    "s"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9009680-5a49-477a-b317-829c2ec41739",
   "metadata": {},
   "source": [
    "model = config['model']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d62885b-89a4-4b43-9cf1-24c23009773b",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b569fd-a72d-4469-bda6-b881fb22d514",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Summary\n",
    "\n",
    "Trained using bboxes that have a padding of 50 or more. Improved the model but it seems like cheating to get the metrics up\n",
    "\n",
    "Decision for which embedder to use is also decided here\n",
    "\n",
    "TODO:\n",
    "- multiple bounding box proposal\n",
    "- start with vit optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7932c74-96f6-4f19-aaf9-ac0a36f6571d",
   "metadata": {},
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b041635-d0bc-4527-80c3-d4fb60995adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fitter.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8917a-f6e0-4070-a094-094c84fd16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(enumerate(vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd7791-6cd0-4d9f-abf8-a8a17a87e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices, masks, target, case = sample[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3006bc-12de-44c7-9262-08a53f84f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = slices.squeeze(1).float().to(device)\n",
    "T = masks.squeeze(1).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ccaa76-292d-42a2-b18b-b5703af1ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa8bab-40f4-47f6-99f5-92cee8c0af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter.loss(y, T[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e0cb6-4c22-477a-93de-1aeeffa7c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c4cf0-8cf1-4e18-8088-6d965a5bc45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148e85c-333c-4c96-af84-d6fba9a31f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = masks[target].squeeze().cpu().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992cdc6-8cbc-46b3-b484-12dcf8f36a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y*300).squeeze().detach().cpu().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697268b-3642-4425-9756-342ea54fddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa1ca4-7e42-4b09-810a-12eb99a98159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.heatmap(x[target].squeeze().cpu(), cmap='gray')\n",
    "\n",
    "truth = patches.Rectangle(\n",
    "    (bbox[0], bbox[1]),\n",
    "    bbox[2] - bbox[0],\n",
    "    bbox[3] - bbox[1],\n",
    "    linewidth=1, edgecolor='g', facecolor='none'\n",
    ")\n",
    "\n",
    "pred = patches.Rectangle(\n",
    "    (y[0], y[1]),\n",
    "    y[2] - y[0],\n",
    "    y[3] - y[1],\n",
    "    linewidth=1, edgecolor='r', facecolor='none'\n",
    ")\n",
    "\n",
    "ax.add_patch(truth)\n",
    "ax.add_patch(pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
