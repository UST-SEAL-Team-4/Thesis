{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38fda1db-7b92-4339-a2f1-08904c240100",
   "metadata": {},
   "source": [
    "# Training method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610af8e1-4371-499a-b4b6-7831fbdf4d59",
   "metadata": {},
   "source": [
    "Train both GCRPN and GCViT at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e7189-9a7c-42b2-b69a-1545c3916b28",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9546c386-d11b-446d-a453-06242b4ef1a4",
   "metadata": {},
   "source": [
    "Copy pasted imports from the final project notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51b5d9-7b44-4666-b666-e6c2c558ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import natsort as ns\n",
    "import re\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "from effdet.efficientdet import HeadNet\n",
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations import Compose, Normalize, Resize, BboxParams\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b817c-a092-4488-8265-9b65064435cd",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b45f747-9903-4a99-aeb1-396578b5cea0",
   "metadata": {},
   "source": [
    "Get all the names of the cases in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9dc0f0-9a86-4893-b21a-dd68b8784c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_label_relative = 'VALDO_Dataset\\Task2'\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "two_directories_up = os.path.abspath(os.path.join(current_directory, \"../\"))\n",
    "\n",
    "# Combine the current directory with the relative path\n",
    "testing_label_absolute = os.path.join(\n",
    "    two_directories_up, testing_label_relative)\n",
    "\n",
    "folders = [item for item in os.listdir(testing_label_absolute) if os.path.isdir(\n",
    "    os.path.join(testing_label_absolute, item))]\n",
    "\n",
    "cases = {\"cohort1\": [], \"cohort2\": [], \"cohort3\": []}\n",
    "# Print the list of folders\n",
    "for folder in folders:\n",
    "    if \"sub-1\" in folder:\n",
    "        cases[\"cohort1\"].append(folder)\n",
    "    elif \"sub-2\" in folder:\n",
    "        cases[\"cohort2\"].append(folder)\n",
    "    else:\n",
    "        cases[\"cohort3\"].append(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9621eae-92b2-46ef-aff2-b12beac5b2ef",
   "metadata": {},
   "source": [
    "Divide the cases according to their cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db3531-6aa8-4142-9cfd-efa4c2658f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort1_labels = []\n",
    "cohort1_ids = []\n",
    "for case in cases[\"cohort1\"]:\n",
    "    label = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_CMB.nii.gz\"\n",
    "    id = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort1_labels.append(label)\n",
    "    cohort1_ids.append(id)\n",
    "# print(\"Label:\", cohort1_labels, cohort1_labels.__len__())\n",
    "# print(\"Ids:\", cohort1_ids, cohort1_ids.__len__())\n",
    "\n",
    "cohort2_labels = []\n",
    "cohort2_ids = []\n",
    "for case in cases[\"cohort2\"]:\n",
    "    label = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_CMB.nii.gz\"\n",
    "    id = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort2_labels.append(label)\n",
    "    cohort2_ids.append(id)\n",
    "# print(\"Label:\", cohort2_labels, cohort2_labels.__len__())\n",
    "# print(\"Ids:\", cohort2_ids, cohort2_ids.__len__())\n",
    "\n",
    "cohort3_labels = []\n",
    "cohort3_ids = []\n",
    "for case in cases[\"cohort3\"]:\n",
    "    label = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_CMB.nii.gz\"\n",
    "    id = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort3_labels.append(label)\n",
    "    cohort3_ids.append(id)\n",
    "# print(\"Label:\", cohort3_labels, cohort3_labels.__len__())\n",
    "# print(\"Ids:\", cohort3_ids, cohort3_ids.__len__())\n",
    "\n",
    "all_labels = cohort1_labels + cohort2_labels + cohort3_labels\n",
    "all_ids = cohort1_ids + cohort2_ids + cohort3_ids\n",
    "\n",
    "\n",
    "# print(all_labels[0])\n",
    "# print(all_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa841e4-de2f-4e2b-a0b4-48e99eb74964",
   "metadata": {},
   "source": [
    "Import valdo dataset class from `valdo.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8750743-815a-4df4-ada4-3fcc14f2e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valdo import VALDODataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1fc18d-976b-4dd5-bfd8-73933557f421",
   "metadata": {},
   "source": [
    "# Other preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f37756-81d6-4ca0-91ab-eb0099db01b1",
   "metadata": {},
   "source": [
    "Transformations used in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688b3b8-b8d9-4e76-8933-9314094931db",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        A.Resize(height=256, width=256, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ],\n",
    "    p=1.0,\n",
    "    bbox_params=A.BboxParams(\n",
    "        format='pascal_voc',\n",
    "        min_area=0,\n",
    "        min_visibility=0,\n",
    "        label_fields=['labels']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4639b-be25-4048-8530-8c1d35f20b4e",
   "metadata": {},
   "source": [
    "Collate for each batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83f1aa-8747-4c54-a284-e4e986fb44d0",
   "metadata": {},
   "source": [
    "This is used to return the slices, targets, and img_ids during each iteration in the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce107f-2bfb-463a-8555-a033f644f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    slices = []\n",
    "    targets = []\n",
    "    img_paths = []\n",
    "    cmb_counts = []\n",
    "\n",
    "    for item in batch:\n",
    "        item_slices, item_targets, item_img_path, item_cmb_counts = item\n",
    "        slices.extend(item_slices)\n",
    "        targets.extend(item_targets)\n",
    "        img_paths.append(item_img_path)\n",
    "        cmb_counts.append(item_cmb_counts)\n",
    "\n",
    "    slices = [torch.stack(tuple(slice_set)) for slice_set in slices]\n",
    "\n",
    "    return slices, targets, img_paths,\n",
    "\n",
    "\n",
    "def euclid_dist(t1, t2):\n",
    "    t1 = np.array(t1)\n",
    "    t2 = np.array(t2)\n",
    "    return np.sqrt(((t1-t2)**2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09dff83-1272-4e05-8d2c-e429149ceb8a",
   "metadata": {},
   "source": [
    "AverageMeter for the summary loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fceca8-029c-4df8-8be0-58615ed1118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5208d6e6-da2d-4237-9be2-0dc7c1861b1e",
   "metadata": {},
   "source": [
    "`get_predicted_marking_validation` returns a dataframe of all the predicted bounding boxes during the validation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a571f3-10e1-4f98-bb0d-4023db2531d2",
   "metadata": {},
   "source": [
    "All the returned bounding boxes have a score greater than the score_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6da2b8-6374-43da-b440-b684f3d4defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_marking_validation(dataset, prediction_list, slice_num, id, score_threshold):\n",
    "    predicted_cmbs = {\n",
    "        'image_id': [],\n",
    "        'slice_num': [],\n",
    "        'x': [],\n",
    "        'y': [],\n",
    "        'w': [],\n",
    "        'h': []\n",
    "    }\n",
    "\n",
    "    for box in prediction_list:\n",
    "        if box[4].item() > score_threshold:\n",
    "            predicted_cmbs['image_id'].append(id)\n",
    "            predicted_cmbs['slice_num'].append(slice_num)\n",
    "            predicted_cmbs['x'].append(box[0].item())\n",
    "            predicted_cmbs['y'].append(box[1].item())\n",
    "            predicted_cmbs['w'].append(box[2].item())\n",
    "            predicted_cmbs['h'].append(box[3].item())\n",
    "\n",
    "    # Convert to DataFrame once at the end\n",
    "    predicted_cmbs_df = pd.DataFrame(predicted_cmbs)\n",
    "    return predicted_cmbs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90994737-643f-4025-a62c-0ba34cc19617",
   "metadata": {},
   "source": [
    "`get_all_marking` returns all the ground truth bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5becb75d-f656-4b36-acca-2bbda7733245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_marking(dataset):\n",
    "    all_cmbs = {\n",
    "        'image_id': [],\n",
    "        'slice_num': [],\n",
    "        'x': [],\n",
    "        'y': [],\n",
    "        'w': [],\n",
    "        'h': []\n",
    "    }\n",
    "    for i in range(len(dataset)):\n",
    "        slices, targets, id, count = dataset[i]\n",
    "        for j in range(len(slices)):\n",
    "            for target in targets[j]['boxes']:\n",
    "                all_cmbs['image_id'].append(id)\n",
    "                all_cmbs['slice_num'].append(j)\n",
    "                all_cmbs['x'].append(target[0].item())\n",
    "                all_cmbs['y'].append(target[1].item())\n",
    "                all_cmbs['w'].append(target[2].item())\n",
    "                all_cmbs['h'].append(target[3].item())\n",
    "\n",
    "    # Convert to DataFrame once at the end\n",
    "    all_cmbs = pd.DataFrame(all_cmbs)\n",
    "    return all_cmbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ab9c5-4872-455f-bed0-297860977cbe",
   "metadata": {},
   "source": [
    "`count_FPTP` counts all the false positives, true positives, and false negatives\n",
    "\n",
    "A dataframe containing the fp, tp, and fp are also returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fe966-66a6-4815-9dfb-e4295678276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_FPTP(all_marking, predicted_marking):\n",
    "    # Initialize\n",
    "    fp = pd.DataFrame(columns=['image_id', 'slice_num', 'x', 'y', 'w', 'h'])\n",
    "    fp_count = 0\n",
    "    tp = pd.DataFrame(columns=['image_id', 'slice_num', 'x', 'y', 'w', 'h'])\n",
    "    tp_count = 0\n",
    "    fn = pd.DataFrame(columns=['image_id', 'slice_num', 'x', 'y', 'w', 'h'])\n",
    "    fn_count = 0\n",
    "\n",
    "    # Merge according to image_id and slice_num\n",
    "    merged_df = pd.merge(predicted_marking, all_marking, on=[\n",
    "                         'image_id', 'slice_num'], suffixes=('_pred', '_true'))\n",
    "\n",
    "    # Get the initial false positives\n",
    "    # Create a key for matching\n",
    "    predicted_marking['key'] = predicted_marking['image_id'] + \\\n",
    "        '_' + predicted_marking['slice_num'].astype(str)\n",
    "    merged_df['key'] = merged_df['image_id'] + \\\n",
    "        '_' + merged_df['slice_num'].astype(str)\n",
    "\n",
    "    # Use isin to identify rows not in merged_df\n",
    "    fp = predicted_marking[~predicted_marking['key'].isin(merged_df['key'])]\n",
    "    fp = fp.drop(columns=['key'])\n",
    "    fp_count += len(fp)\n",
    "\n",
    "    grouped_dict = {}\n",
    "\n",
    "    # Group by image_id and slice_num\n",
    "    grouped = merged_df.groupby(['image_id', 'slice_num'])\n",
    "\n",
    "    # Iterate over the groups and store in the dictionary\n",
    "    for (image_id, slice_num), group in grouped:\n",
    "        key = (image_id, slice_num)\n",
    "        grouped_dict[key] = group\n",
    "\n",
    "    # Get all the counts\n",
    "    for key, df in grouped_dict.items():\n",
    "        x_pred_values = df['x_pred'].values\n",
    "        y_pred_values = df['y_pred'].values\n",
    "        x_true_values = df['x_true'].values\n",
    "        y_true_values = df['y_true'].values\n",
    "\n",
    "        w_pred_values = df['w_pred'].values\n",
    "        h_pred_values = df['h_pred'].values\n",
    "\n",
    "        is_correct = False\n",
    "        for i in range(len(x_pred_values)):\n",
    "            pred_cmb = [x_pred_values[i], y_pred_values[i]]\n",
    "            true_cmb = [x_true_values[i], y_true_values[i]]\n",
    "            dist = euclid_dist(pred_cmb, true_cmb)\n",
    "            if dist > 20:\n",
    "                is_correct = False\n",
    "            else:\n",
    "                is_correct = True\n",
    "                break\n",
    "\n",
    "        new_row = {\n",
    "            'image_id': key[0],\n",
    "            'slice_num': key[1],\n",
    "            'x': x_pred_values[i],\n",
    "            'y': y_pred_values[i],\n",
    "            'w': w_pred_values[i],\n",
    "            'h': h_pred_values[i]\n",
    "        }\n",
    "        temp = pd.DataFrame(new_row, index=[0])\n",
    "\n",
    "        if is_correct:\n",
    "            tp_count += 1\n",
    "            tp = pd.concat([tp, temp], ignore_index=True)\n",
    "        else:\n",
    "            fp_count += 1\n",
    "            fp = pd.concat([fp, temp], ignore_index=True)\n",
    "\n",
    "    all_marking['key'] = all_marking['image_id'] + \\\n",
    "        '_' + all_marking['slice_num'].astype(str)\n",
    "    tp['key'] = tp['image_id'] + '_' + tp['slice_num'].astype(str)\n",
    "    # Use isin to identify rows not in tp\n",
    "    fn = all_marking[all_marking['key'].isin(tp['key'])]\n",
    "    fn = fn.drop(columns=['key'])\n",
    "    fn_count += len(fn)\n",
    "\n",
    "    tp = tp.drop(columns=['key'])\n",
    "\n",
    "    return fp, fp_count, tp, tp_count, fn, fn_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444777ae-d2d5-4239-8ec3-497f0eb7000b",
   "metadata": {},
   "source": [
    "## Fitter Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d766a19-a3cb-4e2d-8c1c-886a12df7c99",
   "metadata": {},
   "source": [
    "TODO: make it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72f19e-c5e8-4de6-b2d0-eae60a451397",
   "metadata": {},
   "source": [
    "# Dataset balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14896485-cd7c-478c-be15-01dc02f1239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VALDODataset(\n",
    "    img_paths=all_ids, ann_paths=all_labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b88df7-2e7f-446d-ba70-2d0882bf994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cmb = [1 if count > 0 else 0 for count in dataset.cmb_counts]\n",
    "\n",
    "df_dataset = pd.DataFrame({\n",
    "    'MRI Scans': dataset.img_paths,\n",
    "    'Segmented Masks': dataset.ann_paths,\n",
    "    'CMB Count': dataset.cmb_counts,\n",
    "    'Has CMB': has_cmb\n",
    "})\n",
    "\n",
    "# df_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac6e95-4edf-4ce1-adaf-64a3120017bc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191bcc6-c884-4945-aacd-4d371c2d043b",
   "metadata": {},
   "source": [
    "## Training and Validation Split (no cross val yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0124aac-754e-4558-9365-695635340dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df_dataset, test_size=0.2, stratify=df_dataset['Has CMB'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80870f21-6ebc-48e2-82cf-d7b8a3190551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VALDODataset(train_df['MRI Scans'].tolist(\n",
    "), train_df['Segmented Masks'].tolist(), transform=transform)\n",
    "val_dataset = VALDODataset(val_df['MRI Scans'].tolist(\n",
    "), val_df['Segmented Masks'].tolist(), transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cacdfe1-ef9c-48af-8a92-2a78eb37af7b",
   "metadata": {},
   "source": [
    "## Run training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35743f43-e7e7-4514-a7e4-377760009a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "\n",
    "    # net = get_net()\n",
    "    net = Model()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=RandomSampler(train_dataset),\n",
    "        pin_memory=False,\n",
    "        drop_last=False,  # drop last one for having same batch size\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(val_dataset),\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val, history = fitter.fit(\n",
    "        train_loader, val_loader)\n",
    "\n",
    "    return best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6288afe6-7cda-4843-a6ca-36bc6e8a0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val, history = run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4944c-71e9-4e83-ac0c-c56b2396c40b",
   "metadata": {},
   "source": [
    "## TODO: export weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacc75c-81b4-4841-8c91-d711b7966d68",
   "metadata": {},
   "source": [
    "testing and validation will be done on a separate notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
