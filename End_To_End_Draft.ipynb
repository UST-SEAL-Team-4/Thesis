{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End model draft 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo:\n",
    "- Show visuaization on the difference of using transform and normalization \n",
    "- Stratified Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd \n",
    "import nibabel as nib\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from project.preprocessing import z_score_normalization, NiftiToTensorTransform, get_transform\n",
    "# from project.training import split_train_val_datasets\n",
    "from project.model import VisionTransformer, ISAVIT\n",
    "from project.dataset import Dataset, VALDODataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from project.utils import collatev2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from project.model.feeder import Feeder\n",
    "from project.utils import memcheck\n",
    "from project import Fitter\n",
    "from project.utils import compute_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(f'Nigel_EndToEnd_log_{datetime.datetime.now().strftime(\"%d%m%y%H%M%S\")}')\n",
    "fh = logging.FileHandler(f'logs/nigel_EndTooEnd{datetime.datetime.now().strftime(\"%d%m%y%H%M%S\")}.log')\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset and select target slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gets the whole dataset from a specific location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lood the raw rmi and maks of the data based on the number of cohors in the dataset\n",
    "## Data  ds.load_raw_mri() can also be changed to ds.load_skullstripped_mri() for the preprocessed data\n",
    "mri = ds.load_raw_mri()\n",
    "masks = ds.load_cmb_masks()\n",
    "# Get the slices of the MRIs \n",
    "slices = [nib.load(x).get_fdata().shape[2] for x in mri]\n",
    "\n",
    "## Create a standard dataframe of the unprocessed data \n",
    "standard_df = pd.DataFrame({\n",
    "    'mri': mri,\n",
    "    'masks': masks,\n",
    "    'slices': slices\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mri</th>\n",
       "      <th>masks</th>\n",
       "      <th>slices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mri  \\\n",
       "0  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "1  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "2  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "\n",
       "                                               masks  slices  \n",
       "0  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...      35  \n",
       "1  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...      35  \n",
       "2  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...      35  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to generate all the target slices for each case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_slice(mri, masks, slices):\n",
    "    if len(mri) != len(masks):\n",
    "        print(f'Unequal amount of mri cases to cmb masks\\t{len(mri)} to {len(masks)}')\n",
    "    if len(mri) != len(slices):\n",
    "        print(f'Unequal amount of mri cases to case slice counts\\t{len(mri)} to {len(slices)}')\n",
    "\n",
    "    # ls = [(mri[i], masks[i], target) for i in range(len(mri)) for target in range(slices[i])]\n",
    "    ls = []\n",
    "    \n",
    "    for i in range(len(mri)):\n",
    "        mask_data = nib.load(masks[i]).get_fdata()\n",
    "        has_microbleed_case = 1 if mask_data.max() > 0 else 0\n",
    "            \n",
    "        for target in range(slices[i]):\n",
    "            has_microbleed_slice = 1 if mask_data[:, :, target].max() > 0 else 0\n",
    "            ls.append((\n",
    "                mri[i], \n",
    "                masks[i], \n",
    "                target, \n",
    "                has_microbleed_case, \n",
    "                has_microbleed_slice\n",
    "            ))\n",
    "            \n",
    "    df = pd.DataFrame(ls, columns=[\n",
    "        'mri',\n",
    "        'masks', \n",
    "        'target', \n",
    "        'has_microbleed_case', \n",
    "        'has_microbleed_slice'\n",
    "    ])\n",
    "    # ls = [(case, target) for case, slices in zip(case, slices) for target in range(slices)]\n",
    "    return df\n",
    "\n",
    "# df = generate_target_slice(mri, masks, slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double check if all the slices matches with the raw dataframe count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar_targets = df.groupby('mri').target.max()\n",
    "# ar_slices = standard_df.groupby('mri').slices.max()\n",
    "# (ar_targets == (ar_slices - 1)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export as metadata(CSV file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('targets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch1 = ds.load_raw_mri(1)\n",
    "data = data[data.mri.isin(ch1)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mri</th>\n",
       "      <th>masks</th>\n",
       "      <th>target</th>\n",
       "      <th>has_microbleed_case</th>\n",
       "      <th>has_microbleed_slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mri  \\\n",
       "0  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "1  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "2  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "3  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "4  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...   \n",
       "\n",
       "                                               masks  target  \\\n",
       "0  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...       0   \n",
       "1  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...       1   \n",
       "2  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...       2   \n",
       "3  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...       3   \n",
       "4  c:\\Users\\nigel\\Documents\\Thesis\\Dataset\\VALDO_...       4   \n",
       "\n",
       "   has_microbleed_case  has_microbleed_slice  \n",
       "0                    1                     0  \n",
       "1                    1                     0  \n",
       "2                    1                     0  \n",
       "3                    1                     0  \n",
       "4                    1                     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7987 cases with 3 columns**\n",
    "- Columns\n",
    "    - mri\n",
    "    - masks\n",
    "    - target slice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (400, 400)\n",
    "rpn_mode = False\n",
    "\n",
    "batch_size = 1\n",
    "collate_fn = collatev2\n",
    "\n",
    "image_size = 400\n",
    "input_output_dim = 2500\n",
    "\n",
    "epochs = 10\n",
    "# epochs = 1\n",
    "loss = nn.MSELoss()\n",
    "lr = 0.00075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = NiftiToTensorTransform(target_shape = target_shape, rpn_mode=rpn_mode) # Hanggang dito lang kaya ng GPU mem ko\n",
    "\n",
    "cases = data.mri\n",
    "masks = data.masks\n",
    "target = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VALDODataset(\n",
    "    cases=cases,\n",
    "    masks=masks,\n",
    "    target=target,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collatev2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collatev2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "from project.model import SliceEmbedding, Autoencoder, Decoder\n",
    "\n",
    "en = SliceEmbedding(\n",
    "    image_size=image_size,\n",
    "    output_dim=input_output_dim,\n",
    ")\n",
    "\n",
    "de = Decoder(\n",
    "    image_size=image_size,\n",
    "    input_dim=input_output_dim\n",
    ")\n",
    "\n",
    "config = {\n",
    "    'model': Autoencoder(en, de).to(device),\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'device': device,\n",
    "    'epochs': epochs,\n",
    "    'loss': loss,\n",
    "    'lr': lr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEFitter(Fitter):\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        loss_history = []\n",
    "        counter = 0\n",
    "        print(\"Training========\")\n",
    "        for batch in train_loader:\n",
    "            Y = []\n",
    "            T = []\n",
    "            for slices, masks, target, case in batch:\n",
    "                if slices is None:\n",
    "                    logger.error(f'CASE NOT WORKING: {case}')\n",
    "                    continue\n",
    "                x = slices.squeeze(1).float().to(self.device)\n",
    "                y = self.model(x)\n",
    "                logger.info(f'MEMORY after X, Y, T to device\\t{memcheck()}')\n",
    "                losses = self.loss(y, x)\n",
    "                self.optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                self.optimizer.step()\n",
    "                loss_history.append(losses.detach().cpu().numpy())\n",
    "            \n",
    "            counter += len(batch)\n",
    "            if counter % 100 == 0:\n",
    "                logger.info(f'Progress:\\t{counter}/{len(dataset)}')\n",
    "                logger.info(f'Current error:\\t{losses}')\n",
    "            \n",
    "            # del losses, Y, T\n",
    "            # torch.cuda.empty_cache()\n",
    "            # logger.info(f'MEMORY after CLEARING MEMORY\\t{memcheck()}')\n",
    "            \n",
    "        return loss_history\n",
    "    def validation(self, val_loader):\n",
    "        print(\"Validating========\")\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            loss_history = []\n",
    "            counter = 0\n",
    "            for batch in val_loader:\n",
    "                Y = []\n",
    "                T = []\n",
    "                for slices, masks, target, case in batch:\n",
    "                    if slices is None:\n",
    "                        logger.error(f'CASE NOT WORKING: {case}')\n",
    "                        continue\n",
    "                    x = slices.squeeze(1).float().to(self.device)\n",
    "                    y = self.model(x)\n",
    "                    losses = self.loss(y, x)\n",
    "                    loss_history.append(losses.detach().cpu().numpy())\n",
    "\n",
    "                    print(\"Vlidation: \",x.shape, y.shape)\n",
    "                counter += len(batch)\n",
    "                if counter % 100 == 0:\n",
    "                    logger.info(f'Progress:\\t{counter}/{len(dataset)}')\n",
    "                    logger.info(f'Current error:\\t{losses}')\n",
    "                \n",
    "                # del losses, Y, T\n",
    "                # torch.cuda.empty_cache()\n",
    "                # logger.info(f'MEMORY after CLEARING MEMORY\\t{memcheck()}')\n",
    "            \n",
    "        return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Autoenfitter = AEFitter(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ==============================\n",
      "Training========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n",
      "torch.Size([35, 1, 2500])\n",
      "torch.Size([35, 1, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "# ae_hist = Autoenfitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae_t_hist, ae_v_hist = ae_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPN Proper training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the latest weights of the encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights\\Encoder_weights_251024111249.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os.path\n",
    "\n",
    "folder_path = r\"weights/\"\n",
    "file_type = r\"\\*pt\"\n",
    "files = glob.glob(folder_path + file_type)\n",
    "weight = max(files, key=os.path.getctime)\n",
    "\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from project.model import RPN\n",
    "\n",
    "config = {\n",
    "    'model': RPN(\n",
    "        input_dim=2500,\n",
    "        output_dim=4,\n",
    "        image_size=300\n",
    "    ).to(device),\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'device': device,\n",
    "    'epochs': 1,\n",
    "    'loss': nn.SmoothL1Loss(),\n",
    "    # 'loss': nn.MSELoss(),\n",
    "    'lr': 0.00001\n",
    "}\n",
    "\n",
    "model = config['model']\n",
    "\n",
    "#Load the embedder weights\n",
    "# model.embedder.load_state_dict(torch.load(weight))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPN Fitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPNFitter(Fitter):\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        loss_history = []\n",
    "        counter = 0\n",
    "        for batch in train_loader:\n",
    "            Y = []\n",
    "            T = []\n",
    "            for slices, masks, target, case in batch:\n",
    "                num_slices = slices.shape[0]\n",
    "                x = slices.squeeze(1).float().to(self.device)\n",
    "                masks = masks.squeeze(1).float().to(self.device)\n",
    "                y = self.model(x, target)\n",
    "                Y.append(y)\n",
    "                T.append(masks[target])\n",
    "            \n",
    "            losses = self.loss(torch.stack(Y), torch.stack(T))\n",
    "            self.optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            self.optimizer.step()\n",
    "            counter += len(batch)\n",
    "            if counter % 100 == 0:\n",
    "                logger.info(f'Progress:\\t{counter}/{len(dataset)}')\n",
    "                logger.info(f'Current error:\\t{losses}')\n",
    "            loss_history.append(losses.detach().cpu().numpy())\n",
    "        return loss_history\n",
    "    \n",
    "\n",
    "fitter = RPNFitter(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rpn_hist \u001b[38;5;241m=\u001b[39m \u001b[43mfitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nigel\\Documents\\Thesis\\Thesis\\project\\model\\fitter.py:23\u001b[0m, in \u001b[0;36mFitter.fit\u001b[1;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# loop with self.epochs\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# train with self.train_one_epoch\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# validate\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation(val_loader)\n",
      "Cell \u001b[1;32mIn[40], line 13\u001b[0m, in \u001b[0;36mRPNFitter.train_one_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m slices\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     12\u001b[0m masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 13\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m Y\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[0;32m     15\u001b[0m T\u001b[38;5;241m.\u001b[39mappend(masks[target])\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nigel\\Documents\\Thesis\\Thesis\\project\\model\\rpn.py:101\u001b[0m, in \u001b[0;36mRPN.forward\u001b[1;34m(self, x, i)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, i):\n\u001b[1;32m--> 101\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     slices \u001b[38;5;241m=\u001b[39m slices\u001b[38;5;241m.\u001b[39mview(slices\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    103\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposenc(slices)\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nigel\\Documents\\Thesis\\Thesis\\project\\model\\rpn.py:69\u001b[0m, in \u001b[0;36mSliceEmbedding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 69\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(out)\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:133\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:1704\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1704\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rpn_hist = fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpn_train_history, rpn_val_history = rpn_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "\n",
    "cases = ds.load_raw_mri()\n",
    "masks = ds.load_cmb_masks()\n",
    "data = pd.read_csv('targets.csv')\n",
    "data.shape\n",
    "\n",
    "ch1 = ds.load_raw_mri(1)\n",
    "data = data[data.mri.isin(ch1)]\n",
    "data.shape\n",
    "\n",
    "cases = data.mri\n",
    "masks = data.masks\n",
    "target = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (512, 512)\n",
    "global_min, global_max = compute_statistics(cases)\n",
    "\n",
    "\n",
    "normalized_transform = NiftiToTensorTransform(\n",
    "    target_shape = target_shape, \n",
    "    normalization=(global_min, global_max)\n",
    ")\n",
    "\n",
    "dataset = VALDODataset(\n",
    "    cases=cases,\n",
    "    masks=masks,\n",
    "    target=target,\n",
    "    transform=normalized_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = get_transform(\n",
    "    height=16,\n",
    "    width=16,\n",
    "    p=1.0,\n",
    "    rpn_mode=False\n",
    ")\n",
    "\n",
    "feeder = Feeder(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collatev2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collatev2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedset = VALDODataset(\n",
    "    cases=cases,\n",
    "    masks=masks,\n",
    "    target=target,\n",
    "    transform=normalized_transform,\n",
    "    # normalization=z_score_normalization,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT Training Proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model': ISAVIT(\n",
    "        d_model=1000,\n",
    "        patch_size=16,\n",
    "        dim_ff=2000\n",
    "    ).to(device),\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'device': device,\n",
    "    'epochs': 10,\n",
    "    # 'loss': nn.BCEWithLogitsLoss(),\n",
    "    'loss': nn.CrossEntropyLoss(),\n",
    "    # 'loss': nn.MSELoss(),\n",
    "    'lr': 0.0000001\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT Feeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTFitter(Fitter):\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        loss_history = []\n",
    "        counter = 0\n",
    "        for batch in train_loader:\n",
    "            Y = []\n",
    "            T = []\n",
    "            for slices, masks, target, case in batch:\n",
    "                num_slices = slices.shape[0]\n",
    "                \n",
    "                regions = feedset.locate_case_by_mri(case)\n",
    "                bboxes = regions[1].view(regions[1].shape[0], -1)\n",
    "                bbox = bboxes[target].int().tolist()\n",
    "                \n",
    "                x = feeder(slices, bbox, 16)\n",
    "                t = feeder(masks, bbox, 16)\n",
    "\n",
    "                x = x.view(num_slices, 1, -1).float().to(self.device)\n",
    "                masks = t.view(num_slices, 1, -1).float().to(self.device)\n",
    "                \n",
    "                y = self.model(x, target)\n",
    "                Y.append(y)\n",
    "                T.append(masks[target])\n",
    "            \n",
    "                losses = self.loss(torch.stack(Y), torch.stack(T))\n",
    "                # losses = self.loss(torch.stack(T), torch.stack(Y))\n",
    "                loss_history.append(losses.detach().cpu().numpy())\n",
    "            self.optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            self.optimizer.step()\n",
    "            counter += len(batch)\n",
    "            if counter % 100 == 0:\n",
    "                logger.info(f'Progress:\\t{counter}/{len(dataset)}')\n",
    "                logger.info(f'Current error:\\t{losses}')\n",
    "        \n",
    "        return loss_history\n",
    "    \n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_history = []\n",
    "            counter = 0\n",
    "            for batch in val_loader:\n",
    "                Y = []\n",
    "                T = []\n",
    "                for slices, masks, target, case in batch:\n",
    "                    num_slices = slices.shape[0]\n",
    "                    \n",
    "                    regions = feedset.locate_case_by_mri(case)\n",
    "                    bboxes = regions[1].view(regions[1].shape[0], -1)\n",
    "                    bbox = bboxes[target].int().tolist()\n",
    "                    \n",
    "                    x = feeder(slices, bbox, 16)\n",
    "                    t = feeder(masks, bbox, 16)\n",
    "\n",
    "                    x = x.view(num_slices, 1, -1).float().to(self.device)\n",
    "                    masks = t.view(num_slices, 1, -1).float().to(self.device)\n",
    "                    \n",
    "                    y = self.model(x, target)\n",
    "                    Y.append(y)\n",
    "                    T.append(masks[target])\n",
    "                \n",
    "                    losses = self.loss(torch.stack(Y), torch.stack(T))\n",
    "                    # losses = self.loss(torch.stack(T), torch.stack(Y))\n",
    "                    loss_history.append(losses.detach().cpu().numpy())\n",
    "                counter += len(batch)\n",
    "                if counter % 100 == 0:\n",
    "                    logger.info(f'Progress:\\t{counter}/{len(dataset)}')\n",
    "                    logger.info(f'Current error:\\t{losses}')\n",
    "            return loss_history\n",
    "        \n",
    "\n",
    "fitter = ViTFitter(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_hist = fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_train_hist, vit_val_hist = vit_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(torch.tensor(np.array(vit_train_hist)).mean(1), label='Training')\n",
    "sns.lineplot(torch.tensor(np.array(vit_val_hist)).mean(1), label='Validation')\n",
    "\n",
    "plt.title(\"Training and Validation History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "s = f'vit_weights/ViT_test12_weights_{datetime.datetime.now().strftime(\"%d%m%y%H%M%S\")}.pt'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = fitter.model\n",
    "sample = next(enumerate(dloader))\n",
    "slices, masks, target, case = sample[1][3]\n",
    "\n",
    "num_slices = slices.shape[0]\n",
    "\n",
    "regions = feedset.locate_case_by_mri(case)\n",
    "bboxes = regions[1].view(regions[1].shape[0], -1)\n",
    "bbox = bboxes[target].int().tolist()\n",
    "\n",
    "x = feeder(slices, bbox, 16)\n",
    "t = feeder(masks, bbox, 16)\n",
    "\n",
    "x = x.view(num_slices, 1, -1).float().to(device)\n",
    "masks = t.view(num_slices, 1, -1).float().to(device)\n",
    "\n",
    "y = model(x, target)\n",
    "# fitter.loss(y,x)\n",
    "\n",
    "sns.heatmap(y.detach().cpu())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
